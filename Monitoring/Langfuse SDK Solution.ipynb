{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solution_intro",
   "metadata": {},
   "source": [
    "# Introducing Langfuse SDK - Solution\n",
    "\n",
    "This notebook demonstrates how to integrate the Langfuse SDK into a Python application to trace and observe language model calls using the low-level SDK. We will use the GPT-2 text generation model from the `transformers` library as an example.\n",
    "\n",
    "This approach provides fine-grained control over tracing individual LLM calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langfuse_signup",
   "metadata": {},
   "source": [
    "## Sign Up for Langfuse\n",
    "\n",
    "Before you begin, you need to sign up for a free Langfuse account to get your API keys. Follow these steps:\n",
    "\n",
    "1.  Go to the Langfuse website: [https://langfuse.com/](https://langfuse.com/)\n",
    "2.  Click on \"Sign Up\".\n",
    "3.  Follow the instructions to create your account.\n",
    "4.  Once logged in, navigate to your project settings to find your **Public Key** and **Secret Key**. You will also need your **Host** URL (usually `https://cloud.langfuse.com`).\n",
    "5.  Keep these keys handy. It is highly recommended to set these as environment variables (`LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST`) before running this notebook for security. Research how to set environment variables in your operating system or within a Jupyter environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_installation",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "We need to install the `langfuse` SDK, `transformers`, and `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution_install_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "!pip install langfuse transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_setup",
   "metadata": {},
   "source": [
    "## 2. Langfuse and Model Setup\n",
    "\n",
    "Import the necessary libraries and initialize Langfuse. Langfuse will automatically pick up your API keys and host from environment variables if they are set. We will also load the GPT-2 model using the `transformers` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution_import_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langfuse import Langfuse\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "# Initialize Langfuse. It reads keys from environment variables by default.\n",
    "# Ensure LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, and LANGFUSE_HOST are set.\n",
    "\n",
    "%env LANGFUSE_SECRET_KEY=sk-lf-30d71f39-9615-4e6b-a0f7-ec1b8d14acf7\n",
    "%env LANGFUSE_PUBLIC_KEY=pk-lf-e3e8cfc3-e32e-4b9b-a02f-53ada416db02\n",
    "%env LANGFUSE_HOST=https://cloud.langfuse.com\n",
    "\n",
    "try:\n",
    "    langfuse = Langfuse()\n",
    "    print(\"Langfuse initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Langfuse: {e}\")\n",
    "    print(\"Please ensure LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, and LANGFUSE_HOST environment variables are set correctly.\")\n",
    "    langfuse = None # Set to None if initialization fails\n",
    "\n",
    "# Initialize GPT-2 model\n",
    "# Using a pipeline simplifies text generation\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42) # Set seed for reproducibility\n",
    "\n",
    "print(\"GPT-2 model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_tracing",
   "metadata": {},
   "source": [
    "## 3. Tracing with Langfuse (Low-Level SDK)\n",
    "\n",
    "We will now trace a single text generation call using the Langfuse low-level SDK. This involves creating a `generation` object before the LLM call and ending it with the output afterwards. This method gives explicit control over what is traced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution_trace_call",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input prompt\n",
    "prompt = \"The quick brown fox jumps over the lazy dog because\"\n",
    "\n",
    "try:\n",
    "    # Create a trace\n",
    "    trace = langfuse.trace(\n",
    "        name=\"GPT-2 Trace\",\n",
    "        input=prompt,\n",
    "        metadata={\"task\": \"text-completion\"}\n",
    "    )\n",
    "\n",
    "    # Create a generation associated with the trace\n",
    "    generation = trace.generation(\n",
    "        name=\"GPT-2 Generation\",\n",
    "        model=\"gpt2\",\n",
    "        model_parameters={\n",
    "            \"max_length\": 100,\n",
    "            \"num_return_sequences\": 1\n",
    "        },\n",
    "        input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        metadata={\"task\": \"text-completion\"}\n",
    "    )\n",
    "\n",
    "    # Generate output using GPT-2\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_length=100,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id\n",
    "    )[0]['generated_text']\n",
    "\n",
    "    # End the generation with the output\n",
    "    generation.end(output=output)\n",
    "\n",
    "    # Update the trace with the output\n",
    "    trace.update(output=output)\n",
    "\n",
    "    print(f\"Generated Text:\\n{output}\")\n",
    "    print(\"Check the Langfuse UI for the trace.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle exceptions and end the generation with error status\n",
    "    if 'generation' in locals() and generation:\n",
    "        generation.end(level=\"ERROR\", status=\"ERROR\", extra={\"error_message\": str(e)})\n",
    "    print(f\"An error occurred during text generation or tracing: {e}\")\n",
    "\n",
    "# Flush Langfuse events\n",
    "print(\"Flushing Langfuse events...\")\n",
    "langfuse.flush()\n",
    "print(\"Events flushed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_view_trace",
   "metadata": {},
   "source": [
    "## 4. View the Trace in Langfuse\n",
    "\n",
    "After running the previous cell (and if Langfuse was initialized successfully), a trace for the GPT-2 generation will be sent to your Langfuse project. Go to your Langfuse project UI ([https://cloud.langfuse.com/](https://cloud.langfuse.com/) or your self-hosted instance) to view the trace details. You should see the input prompt, the generated output, model parameters, metadata, and timing information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
