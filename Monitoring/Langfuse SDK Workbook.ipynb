{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "workbook_intro",
   "metadata": {},
   "source": [
    "# Introducing Langfuse SDK - Workbook\n",
    "\n",
    "This workbook will guide you through integrating the Langfuse SDK into a Python application to trace and observe language model calls using the low-level SDK. We will use the GPT-2 text generation model from the `transformers` library as an example.\n",
    "\n",
    "By the end of this workbook, you will be able to:\n",
    "\n",
    "1.  Install the Langfuse SDK.\n",
    "2.  Configure Langfuse with your API keys.\n",
    "3.  Use Langfuse to trace a single LLM call using the low-level SDK.\n",
    "4.  View the trace in the Langfuse UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langfuse_signup_workbook",
   "metadata": {},
   "source": [
    "## Sign Up for Langfuse\n",
    "\n",
    "Before you begin, you need to sign up for a free Langfuse account to get your API keys. Follow these steps:\n",
    "\n",
    "1.  Go to the Langfuse website: [https://langfuse.com/](https://langfuse.com/)\n",
    "2.  Click on \"Sign Up\".\n",
    "3.  Follow the instructions to create your account.\n",
    "4.  Once logged in, navigate to your project settings to find your **Public Key** and **Secret Key**. You will also need your **Host** URL (usually `https://cloud.langfuse.com`).\n",
    "5.  Keep these keys handy. It is highly recommended to set these as environment variables (`LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST`) before running this notebook for security. Research how to set environment variables in your operating system or within a Jupyter environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workbook_installation",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "We need to install the `langfuse` SDK, `transformers`, and `torch`. Use pip to install these libraries in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workbook_install_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Install langfuse, transformers, and torch using pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workbook_setup",
   "metadata": {},
   "source": [
    "## 2. Langfuse and Model Setup\n",
    "\n",
    "Import the necessary libraries from `langfuse` and `transformers`. Initialize the Langfuse SDK. Langfuse will automatically pick up your API keys and host from environment variables if they are set. Include a try-except block to catch potential initialization errors and print a helpful message.\n",
    "\n",
    "Then, load the GPT-2 model using `transformers.pipeline` for text generation and set a seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workbook_import_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# TODO: Import Langfuse from langfuse\n",
    "# TODO: Import pipeline and set_seed from transformers\n",
    "\n",
    "# TODO: Initialize Langfuse within a try-except block. Research how to initialize Langfuse.\n",
    "langfuse = None # Replace with your code\n",
    "\n",
    "# TODO: Initialize the GPT-2 text generation pipeline with the 'gpt2' model\n",
    "generator = None # Replace with your code\n",
    "# TODO: Set the seed for reproducibility (e.g., 42)\n",
    "\n",
    "print(\"Langfuse initialized and GPT-2 model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workbook_tracing",
   "metadata": {},
   "source": [
    "## 3. Tracing with Langfuse (Low-Level SDK)\n",
    "\n",
    "Now, let's trace a single text generation call using the Langfuse low-level SDK. This involves creating a `generation` object before the LLM call and ending it with the output afterwards. This method gives explicit control over what is traced.\n",
    "\n",
    "Define the input prompt. Then, if Langfuse was initialized successfully, create a `generation` object using `langfuse.generation()`. Include parameters like `name`, `model`, `model_parameters`, `input`, and `metadata`. Research the parameters available for `langfuse.generation()`.\n",
    "\n",
    "Make the GPT-2 generation call using the `generator` pipeline. Finally, end the `generation` object with the generated output using `generation.end()`. Include a try-except block around the generation and tracing code to handle potential errors and ensure the `generation` is ended with an error status if necessary. Research how to end a generation with an error using `generation.end()` with `level=\"ERROR\"` and `status=\"ERROR\"`.\n",
    "\n",
    "After the try-except block, call `langfuse.flush()` to ensure the tracing data is sent to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workbook_trace_call",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the input prompt for the LLM\n",
    "prompt = None # Replace with your code\n",
    "\n",
    "try:\n",
    "    # TODO: Create a 'generation' event in Langfuse before the LLM call\n",
    "    generation = None # Replace with your code\n",
    "\n",
    "    # TODO: Make the GPT-2 generation call using the generator pipeline\n",
    "    output = None # Replace with your code\n",
    "\n",
    "    # TODO: End the 'generation' event with the output\n",
    "    pass # Replace with your code\n",
    "\n",
    "    print(f\"Generated Text:\\n{output}\")\n",
    "    print(\"Check the Langfuse UI for the trace.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # TODO: If an error occurs during generation, end the generation with an error status\n",
    "    if 'generation' in locals() and generation:\n",
    "         pass # Replace with your code to end the generation with error details\n",
    "    print(f\"An error occurred during text generation or tracing: {e}\")\n",
    "\n",
    "# TODO: Call langfuse.flush() to ensure events are sent\n",
    "print(\"Flushing Langfuse events...\")\n",
    "pass # Replace with your code\n",
    "print(\"Events flushed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workbook_view_trace",
   "metadata": {},
   "source": [
    "## 4. View the Trace in Langfuse\n",
    "\n",
    "After running the previous cell (and if Langfuse was initialized successfully), a trace for the GPT-2 generation will be sent to your Langfuse project. Go to your Langfuse project UI ([https://cloud.langfuse.com/](https://cloud.langfuse.com/)) to view the trace details. You should see the input prompt, the generated output, model parameters, metadata, and timing information. Explore the UI to understand how Langfuse visualizes your LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5c04e-82a8-41f0-8eeb-cb126782aaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
